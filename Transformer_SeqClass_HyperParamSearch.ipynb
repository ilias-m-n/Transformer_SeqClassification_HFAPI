{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoiMafe4IZH2"
   },
   "source": [
    "# Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13747,
     "status": "ok",
     "timestamp": 1706230448765,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "BzaTHUtWcb4T"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "from datasets import (\n",
    "     load_from_disk, \n",
    "     load_metric, \n",
    "     DatasetDict, \n",
    "     load_dataset\n",
    ")\n",
    "import evaluate\n",
    "from transformers import (\n",
    "     AutoTokenizer,\n",
    "     DataCollatorWithPadding,\n",
    "     TrainingArguments,\n",
    "     AutoModelForSequenceClassification,\n",
    "     Trainer,\n",
    "     logging,s\n",
    "     AdamW,\n",
    "     get_scheduler,\n",
    "\n",
    ")\n",
    "import torch\n",
    "from ray import tune, train\n",
    "import pickle\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "import utility.utility as util\n",
    "import utility.CustomTrainer as ct\n",
    "import utility.ModelConfig as mc\n",
    "import utility.CustomCallback as cb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filepath to project-root folder, needs to be set manually if not directly called from project folder.\n",
    "\"\"\"\n",
    "path_cwd = os.getcwd()\n",
    "\n",
    "\"\"\"\n",
    "Disables/enables progress bars during training of model.\n",
    "-\"True\": no progress bars shown during training\n",
    "-\"False\": progress bars shown during training\n",
    "\"\"\"\n",
    "_disable_tqdm = False\n",
    "\n",
    "\"\"\"\n",
    "Save checkpoints strategy during training runs. Checkpoints are needed to resume training from specific stages.\n",
    "Checkpoints require a lot of disk space. Turn off if disk space limit.\n",
    "-\"no\": no checkpoints saved\n",
    "-\"epoch\": checkpoint saved after every epoch\n",
    "\"\"\"\n",
    "_save_strategy = \"no\"\n",
    "\n",
    "\"\"\"\n",
    "Number of trials to run during this run of hyperparameter search.\n",
    "\"\"\"\n",
    "_num_trials = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First run or continuation of hyperparameter search (HPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Boolean flag to indicate first run or continuation of HPS.\n",
    "-\"True\": First run\n",
    "-\"False\": Continuation - set _name_config_file below!\n",
    "\"\"\"\n",
    "_flag_first_run = True\n",
    "\n",
    "\"\"\"\n",
    "Set name of ModelConfig file for continuation of HPS.\n",
    "\"\"\"\n",
    "_name_config_file = \"\"\n",
    "\n",
    "\"\"\"\n",
    "Filepath to ModelConfig file.\n",
    "\"\"\"\n",
    "path_file_modelconfig = os.path.join(\"modelconfigs\", _name_config_file)\n",
    "\n",
    "\"\"\"\n",
    "Load ModelConfig for continuation of HPS.\n",
    "\"\"\"\n",
    "model_config = None\n",
    "if not _flag_first_run:\n",
    "    with open(os.path.join(path_cwd, path_file_modelconfig), \"rb\") as f:\n",
    "        model_config = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure model behavior (first run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description of downstream classification task.\n",
    "\"\"\"\n",
    "_task = \"Binary Classification _ with study object and hps log history\"\n",
    "\n",
    "\"\"\"\n",
    "Pretrained transformer base model to be used during finetuning on downstream task.\n",
    "This has to be picked from the pre-trained models on HuggingFace\n",
    "in order to be compatible with the Trainer API.\n",
    "\"\"\"\n",
    "_base_model = \"roberta-base\"\n",
    "\n",
    "\"\"\"\n",
    "Boolean flag to reset classification head.\n",
    "Ff _base_model has already been finetuned on a prio classificaion task,\n",
    "we need to reset its classification head to allow for new task.\n",
    "-\"True\": reset model head\n",
    "-\"False\": don't reset model head\n",
    "\"\"\"\n",
    "_reset_model_head = False\n",
    "\n",
    "\"\"\"\n",
    "Select loss function.\n",
    "Three custom loss functions have been implemented with utility.CustomTrainer:\n",
    "  f1: soft-f1 score\n",
    "  mcc: soft-mcc\n",
    "  wce: weighted cross entropy\n",
    "  ce: standard cross entropy\n",
    "\"\"\"\n",
    "_loss_fct = \"ce\"\n",
    "    \n",
    "\"\"\"\n",
    "Weighting scheme, only relevant when weighted-cross-entropy or other weighted\n",
    "loss schemes are used.\n",
    "\"\"\"\n",
    "_weight_scheme = \"rev_prop\"\n",
    "\n",
    "\"\"\"\n",
    "Set evaluation metrics to be listed during training/evaluation:\n",
    "\"\"\"\n",
    "_eval_metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"matthews_correlation\"]\n",
    "  \n",
    "\n",
    "\"\"\"\n",
    "Specify which metric should be maximized/minimized during hyperparameter-search\n",
    "- \"eval_matthews_correlation\": MCC\n",
    "- \"eval_f1\": F1\n",
    "- \"eval_loss\": Cross-Entropy\n",
    "- any other metric passed to the compute_metrics function\n",
    "\n",
    "Note also specify direction of optimization: \"maximize\"/\"minimize\"\n",
    "\"\"\"\n",
    "_metric_best_model = \"eval_matthews_correlation\"\n",
    "_metric_direction = \"maximize\"\n",
    "\n",
    "\"\"\"\n",
    "Employ freezing of layers, options:\n",
    "\"unfrozen\": all layers unfrozen\n",
    "\"frozen\": some transformer layers frozen\n",
    "\"\"\"\n",
    "_frozen = \"unfrozen\"\n",
    "\n",
    "\"\"\"\n",
    "Location of training dataset.\n",
    "\"True\": HuggingFace Hub\n",
    "\"False\": local directory\n",
    "\"\"\"\n",
    "_from_hub = True\n",
    "\n",
    "\"\"\"\n",
    "Name of dataset on HuggingFace Hub.\n",
    "\"\"\"\n",
    "_dataset_name_hub = \"HalaJada/FinStmts_ConsUncons_Sliding_English_SeqClass\"\n",
    "\n",
    "\"\"\"\n",
    "Name of directory that contains the local dataset.\n",
    "\"\"\"\n",
    "_dataset_name_local = \"\"\n",
    "    \n",
    "\"\"\"\n",
    "Boolean flag to indicate majority voting/multi-segment approach\n",
    "\"\"\"\n",
    "_flag_mv = False\n",
    "\n",
    "\"\"\"\n",
    "Name of HPS study\n",
    "\"\"\"\n",
    "_study_name = \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure using ModelConfig (continuation of HPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If continuation of HPS study, config settings loaded from ModelConfig.\n",
    "\"\"\"\n",
    "if not _flag_first_run:\n",
    "    _task = model_config.task\n",
    "    _base_model = model_config.base_model\n",
    "    _reset_model_head = model_config.reset_model_head\n",
    "    _loss_fct = model_config.loss_fct\n",
    "    _weight_scheme = model_config.weight_scheme\n",
    "    _eval_metrics = model_config.eval_metrics\n",
    "    _metric_best_model = model_config.metric_best_model\n",
    "    _metric_direction = model_config.metric_direction\n",
    "    _frozen = model_config.frozen\n",
    "    _from_hub = model_config.from_hub\n",
    "    _dataset_name_hub = model_config.dataset_name_hub\n",
    "    _dataset_name_local = model_config.dataset_name_local\n",
    "    _flag_mv = model_config.flag_mv\n",
    "    _study_name = model_config.study_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrZ91MToIwEf"
   },
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1706230452844,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "iGkjtCJ6yAgG"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Timestamp of initial training. Used for file and directory naming schemes\n",
    "\"\"\"\n",
    "timestamp = datetime.now().strftime(\"%d_%m_%y_%H_%M\")\n",
    "if not _flag_first_run:\n",
    "    timestamp = model_config.timestamp_initial\n",
    "\n",
    "\"\"\"\n",
    "Some model names contain '/' characters which create issues with file and directory pathing.\n",
    "We replace them with '__' only for naming purposes\n",
    "\"\"\"\n",
    "base_model_altered = re.sub(r'/', '___', _base_model)\n",
    "\n",
    "\"\"\"\n",
    "Name of dataset, used to name model_config. Also replaces \"/\" with \"_\".\n",
    "\"\"\"\n",
    "dataset_name = re.sub(r'/', '_',_dataset_name_hub) if _from_hub else _dataset_name_local\n",
    "\n",
    "\"\"\"\n",
    "Directory path for training data. \n",
    "\"\"\"\n",
    "path_initial_training =  os.path.join(\"training_data\" , base_model_altered, \"initial_training\" + \"_\" + timestamp)\n",
    "\n",
    "\"\"\"\n",
    "Select weighting scheme, only needed when using weighted cost functions.\n",
    "Functions can be found in utility.utility.py\n",
    "\"\"\"\n",
    "class_weighting_schemes = {\"rev_prop\": util.get_reverse_prop_class_weights}\n",
    "\n",
    "\"\"\"\n",
    "Path to folder with local dataset.\n",
    "\"\"\"\n",
    "path_dataset_local = os.path.join(\"datasets\" , _dataset_name_local)\n",
    "\n",
    "\"\"\"\n",
    "Name and path to ModelConfig object file.\n",
    "\"\"\"\n",
    "file_modelconfig = \"ModelConfig_\" + base_model_altered + \"_\" + dataset_name + \"_\" + timestamp + \".pkl\"\n",
    "path_file_modelconfig = os.path.join(\"modelconfigs\", file_modelconfig)\n",
    "\n",
    "\"\"\"\n",
    "Path to sqlite-database with optuna HPS-study data.\n",
    "\"\"\"\n",
    "path_study_db = os.path.join(\"study_dbs\", _study_name + \"_\" + base_model_altered + \"_\" + dataset_name + \"_\" + timestamp + \".db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYAAghnjIzBt"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVotGcMsQLKC"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1706230452844,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "dnPxVcJqQLSC"
   },
   "outputs": [],
   "source": [
    "raw_datasets = util.load_data(_from_hub, _dataset_name_hub, os.path.join(path_cwd, path_dataset_local))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine number of labels/classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = util.get_no_labels(raw_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weighting_schemes[_weight_scheme](raw_datasets)\n",
    "if not _flag_first_run:\n",
    "    class_weights = model_config.class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dY2CaIW5QCY3"
   },
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3178,
     "status": "ok",
     "timestamp": 1706230456007,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "w7qbphxLQAia",
    "outputId": "a5abb768-5382-4ba6-ba17-ee09ade93c44"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(_base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MUIwuMIQ0Hx"
   },
   "source": [
    "## Function that returns the Tokenizer - needed to employ data mapping.\n",
    "\n",
    "Note: Adjust this to desired task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1706230456008,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "6F83g3QqQAo3"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwQnmO5sRKgG"
   },
   "source": [
    "## Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2328,
     "status": "ok",
     "timestamp": 1706230458326,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "QKBC_DDhc0sY"
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvgXUeGJRZEg"
   },
   "source": [
    "## Instantiate DataCollator\n",
    "Note: DataCollatorWithPadding allows for dynamic padding for individual batches. Only use with GPUs. For TPUs, use max_length padding attribute with Tokenizer instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1706230458327,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "LWJoWdWJRZMe"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJWBvuj_JL8y"
   },
   "source": [
    "## Create instance of TrainingArguments\n",
    "\n",
    "Adjust to desired behaviour. Most arguments learned during hyperparameter-search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create instance of class TrainingArguments.\n",
    "\"\"\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = os.path.join(path_cwd, path_initial_training),\n",
    "    save_strategy = _save_strategy,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    logging_strategy = \"epoch\",\n",
    "    metric_for_best_model = _metric_best_model,\n",
    "    disable_tqdm = _disable_tqdm,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjtjOcw3JQ-E"
   },
   "source": [
    "## Model Initialzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we supply two model init functions, one that freezes a number of encoder layers and\n",
    "one that leaves all unfrozen.\n",
    "\n",
    "Pass desired init function to Trainer below.\n",
    "\n",
    "Gradual unfreezing helps to strike a balance between leveraging pre-trained\n",
    "knowledge and adapting to task-specific data. By unfreezing layers gradually\n",
    "during training, the model learns to prioritize retaining general linguistic\n",
    "knowledge in the early layers while fine-tuning the higher layers to adapt to\n",
    "task-specific nuances. This mitigates overfitting by allowing the model to\n",
    "gradually specialize on the new task without abruptly forgetting the\n",
    "linguistic representations learned during pre-training, resulting in more\n",
    "effective adaptation and improved generalization to the target task.\n",
    "\n",
    "Note: When utilizing gradual unfreezing you will have to train the model in\n",
    "multiple steps. Gradually unfreezing ever more layers during training.\n",
    "You will observe slower convergence, as such this will take more time.\n",
    "\n",
    "Note: Depending on the choice of a base model and the desired number of layers\n",
    "to freeze the model_init_frozen function might have to be adjusted.\n",
    "To see which layers are available run:\n",
    "\n",
    "  for name, param in model.named_parameters():\n",
    "    print(name, param)\n",
    "\n",
    "Observe entire model architecture and note layers you wish to freeze. Adjust\n",
    "*conditional statement accordingly.\n",
    "\n",
    "# https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def model_init_frozen(freeze_layers):\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(_base_model, num_labels=num_labels, return_dict=True, ignore_mismatched_sizes=_reset_model_head)\n",
    "  for name, param in model.named_parameters():\n",
    "    # *conditional statement: currently all encoder layers are frozen\n",
    "    freeze_layers = [\"layer.\" + str(i) for i in range(11)]\n",
    "    for fl in freeze_layers:\n",
    "      if fl in name:\n",
    "        param.requires_grad = False\n",
    "  return model\n",
    "\n",
    "def model_init():\n",
    "  return AutoModelForSequenceClassification.from_pretrained(_base_model, num_labels=num_labels, return_dict=True, ignore_mismatched_sizes = _reset_model_head)\n",
    "\n",
    "\n",
    "model_inits = {\"unfrozen\": model_init, \"frozen\": model_init_frozen}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create evaluation metric object and compute function to pass to Trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_metrics = evaluate.combine(_eval_metrics)\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return clf_metrics.compute(predictions = predictions, references = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvjtaX67SAxi"
   },
   "source": [
    "## Initialize CustomTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5134,
     "status": "ok",
     "timestamp": 1706230474466,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "YvWoN2ipR71V",
    "outputId": "9c58e942-0787-459e-ef4b-e90a046b375f"
   },
   "outputs": [],
   "source": [
    "trainer = ct.CustomTrainer(\n",
    "    type_loss = _loss_fct,\n",
    "    model_init = model_inits[_frozen],\n",
    "    class_weights = class_weights,\n",
    "    args = training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and add CustomCallback to Trainer. Allows us to save training logs after each hyperparameter trial run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = cb.CustomCallback(trainer)\n",
    "trainer.add_callback(callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJ7ygag4SIFV"
   },
   "source": [
    "## (Optional) Create and assign an Optimizer and Scheduler\n",
    "\n",
    "When using the HuggingFace Trainer API for hyperparameter search, we can no longer use the \"optimizer\" argument directly. Instead we need to create instances of both the optimizer and scheduler class, and then pass both to Trainer object.\n",
    "\n",
    "Note: This is optional, as we could skip the following step and use the defaults. Included in case some custom behaviour is desired. Remove \"#\" to uncomment passing of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1706230474466,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "DjaTybKZR75P",
    "outputId": "8a030538-588d-4b87-ab8e-3b9e8cb1e4dc"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(trainer.model.parameters())\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = training_args.num_train_epochs * tokenized_datasets[\"train\"].num_rows\n",
    "\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Pass instances to Trainer\n",
    "\"\"\"\n",
    "#trainer.optimizers = (optimizer, lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzY5_Rkj5DsG"
   },
   "source": [
    "# Hyperparameter Search via Optuna\n",
    "\n",
    "Adjust hyperparameters and their ranges as desired\n",
    "\n",
    "\n",
    "Note: warmup_ratio fulfills a somewhat similar role to freezing. It is also often used to stabilize training at the beginning and avoid large weight updates.\n",
    "\n",
    "https://towardsdatascience.com/state-of-the-art-machine-learning-hyperparameter-optimization-with-optuna-a315d8564de1\n",
    "\n",
    "https://huggingface.co/docs/transformers/hpo_train\n",
    "\n",
    "https://github.com/bayesian-optimization/BayesianOptimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1706230474466,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "otwC5-wurHsq"
   },
   "outputs": [],
   "source": [
    "# Define objective function that later selects best model based upon specific metric\n",
    "def compute_objective(metrics):\n",
    "  return metrics[_metric_best_model]\n",
    "\n",
    "# Define search space for hyperparamter tuning\n",
    "def optuna_hp_space(trial):\n",
    "  return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16]),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 3),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-5, 1e-1),\n",
    "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0, 1e-1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7ILtPjkStWa"
   },
   "source": [
    "## Run Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 9443600,
     "status": "ok",
     "timestamp": 1706239918060,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "nk8zx24BStiR",
    "outputId": "7856031a-a010-4b67-c0ca-4537ac02ad86"
   },
   "outputs": [],
   "source": [
    "# Run hyperparameter search\n",
    "best_run = trainer.hyperparameter_search(\n",
    "    direction=_metric_direction,\n",
    "    backend=\"optuna\",\n",
    "    hp_space = optuna_hp_space,\n",
    "    n_trials = _num_trials,\n",
    "    compute_objective = compute_objective,\n",
    "    study_name=_study_name,\n",
    "    storage= \"sqlite:///\" + os.path.join(path_cwd, path_study_db),\n",
    "    load_if_exists=True,\n",
    "    )\n",
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process HPS log history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps_log_df = util.process_hps_log_history(callback.all_log_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ModelConfig File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _flag_first_run:\n",
    "    model_config = mc.ModelConfig(timestamp = timestamp, \n",
    "                              base_model = _base_model, \n",
    "                              reset_model_head = _reset_model_head,\n",
    "                              task = _task, \n",
    "                              loss_fct = _loss_fct, \n",
    "\n",
    "                              from_hub = _from_hub,\n",
    "                              dataset_name_hub = _dataset_name_hub,\n",
    "                              dataset_name_local = _dataset_name_local,\n",
    "                              path_dataset_local = path_dataset_local, \n",
    "\n",
    "                              num_labels = num_labels,\n",
    "                              weight_scheme = _weight_scheme, \n",
    "                              class_weights = class_weights,\n",
    "                              eval_metrics = _eval_metrics,\n",
    "                              metric_best_model = _metric_best_model, \n",
    "                              metric_direction = _metric_direction,\n",
    "                              \n",
    "                              num_trials = _num_trials,  \n",
    "                              frozen = _frozen,  \n",
    "                              path_initial_training = path_initial_training,\n",
    "                              best_run = best_run,\n",
    "                              hps_log_df = hps_log_df,\n",
    "                              flag_mv = _flag_mv,\n",
    "                              study_name = _study_name,\n",
    "                              path_study_db = path_study_db)\n",
    "else:\n",
    "    # update model_config\n",
    "    model_config.no_trials = model_config.num_trials + _num_trials\n",
    "    model_config.best_run = best_run\n",
    "    model_config.hps_log_df = util.merge_hps_log_histories(model_config.hps_log_df, hps_log_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tAPuUgMgYrS"
   },
   "source": [
    "# Save ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1706239918061,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "7sOVEWcCgBsn"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(path_cwd, path_file_modelconfig), 'wb') as f:\n",
    "    pickle.dump(model_config, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv_ml_bert",
   "language": "python",
   "name": "venv_ml_bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
