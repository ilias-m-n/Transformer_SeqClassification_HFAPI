{"cells":[{"cell_type":"markdown","metadata":{"id":"XoiMafe4IZH2"},"source":["# Package Imports"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":460,"status":"ok","timestamp":1708013970643,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"},"user_tz":-60},"id":"BzaTHUtWcb4T"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import re\n","\n","\n","from datasets import (\n","     load_from_disk,\n","     load_metric,\n","     DatasetDict,\n","     load_dataset\n",")\n","import evaluate\n","from transformers import (\n","     AutoTokenizer,\n","     DataCollatorWithPadding,\n","     TrainingArguments,\n","     AutoModelForSequenceClassification,\n","     Trainer,\n","     logging,\n","     AdamW,\n","     get_scheduler,\n","\n",")\n","import torch\n","from ray import tune, train\n","import pickle\n","import optuna\n","from datetime import datetime\n","import utility.utility as util\n","import utility.CustomTrainer as ct\n","import utility.ModelConfig as mc\n","import utility.CustomCallback as cb"]},{"cell_type":"markdown","metadata":{"id":"YTnnyMEJcwNC"},"source":["# Global Settings:"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"vNOhhJYicwNC","executionInfo":{"status":"ok","timestamp":1708013970979,"user_tz":-60,"elapsed":4,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"}}},"outputs":[],"source":["\"\"\"\n","Filepath to project-root folder, needs to be set manually if not directly called from project folder.\n","\"\"\"\n","path_cwd = os.getcwd()\n","\n","\"\"\"\n","Disables/enables progress bars during training of model.\n","-\"True\": no progress bars shown during training\n","-\"False\": progress bars shown during training\n","\"\"\"\n","_disable_tqdm = False\n","\n","\"\"\"\n","Save checkpoints strategy during training runs. Checkpoints are needed to resume training from specific stages.\n","Checkpoints require a lot of disk space. Turn off if disk space limit.\n","-\"no\": no checkpoints saved\n","-\"epoch\": checkpoint saved after every epoch\n","\"\"\"\n","_save_strategy = \"no\"\n","\n","\"\"\"\n","Number of trials to run during this run of hyperparameter search.\n","\"\"\"\n","_num_trials = 1"]},{"cell_type":"markdown","metadata":{"id":"LQ6dVtl-cwND"},"source":["# First run or continuation of hyperparameter search (HPS)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"BOST2LxCcwND","executionInfo":{"status":"ok","timestamp":1708013970979,"user_tz":-60,"elapsed":4,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"}}},"outputs":[],"source":["\"\"\"\n","Boolean flag to indicate first run or continuation of HPS.\n","-\"True\": First run\n","-\"False\": Continuation - set _name_config_file below!\n","\"\"\"\n","_flag_first_run = False\n","\n","\"\"\"\n","Set name of ModelConfig file for continuation of HPS.\n","\"\"\"\n","_name_config_file = \"ModelConfig_roberta-base_HalaJada_FinStmts_ConsUncons_Sliding_English_SeqClass_15_02_24_15_58.pkl\"\n","\n","\"\"\"\n","Filepath to ModelConfig file.\n","\"\"\"\n","path_file_modelconfig = os.path.join(\"modelconfigs\", _name_config_file)\n","\n","\"\"\"\n","Load ModelConfig for continuation of HPS.\n","\"\"\"\n","model_config = None\n","if not _flag_first_run:\n","    with open(os.path.join(path_cwd, path_file_modelconfig), \"rb\") as f:\n","        model_config = pickle.load(f)"]},{"cell_type":"markdown","metadata":{"id":"pgXUabKScwNE"},"source":["# Configure model behavior (first run)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"Lhmar1iLcwNE","executionInfo":{"status":"ok","timestamp":1708013970980,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"}}},"outputs":[],"source":["\"\"\"\n","Description of downstream classification task.\n","\"\"\"\n","_task = \"Binary Classification _ with study object and hps log history\"\n","\n","\"\"\"\n","Pretrained transformer base model to be used during finetuning on downstream task.\n","This has to be picked from the pre-trained models on HuggingFace\n","in order to be compatible with the Trainer API.\n","\"\"\"\n","_base_model = \"roberta-base\"\n","\n","\"\"\"\n","Boolean flag to reset classification head.\n","Ff _base_model has already been finetuned on a prio classificaion task,\n","we need to reset its classification head to allow for new task.\n","-\"True\": reset model head\n","-\"False\": don't reset model head\n","\"\"\"\n","_reset_model_head = False\n","\n","\"\"\"\n","Select loss function.\n","Three custom loss functions have been implemented with utility.CustomTrainer:\n","  f1: soft-f1 score\n","  mcc: soft-mcc\n","  wce: weighted cross entropy\n","  ce: standard cross entropy\n","\"\"\"\n","_loss_fct = \"ce\"\n","\n","\"\"\"\n","Weighting scheme, only relevant when weighted-cross-entropy or other weighted\n","loss schemes are used.\n","\"\"\"\n","_weight_scheme = \"rev_prop\"\n","\n","\"\"\"\n","Set evaluation metrics to be listed during training/evaluation:\n","\"\"\"\n","_eval_metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"matthews_correlation\"]\n","\n","\n","\"\"\"\n","Specify which metric should be maximized/minimized during hyperparameter-search\n","- \"eval_matthews_correlation\": MCC\n","- \"eval_f1\": F1\n","- \"eval_loss\": Cross-Entropy\n","- any other metric passed to the compute_metrics function\n","\n","Note also specify direction of optimization: \"maximize\"/\"minimize\"\n","\"\"\"\n","_metric_best_model = \"eval_matthews_correlation\"\n","_metric_direction = \"maximize\"\n","\n","\"\"\"\n","Employ freezing of layers, options:\n","\"unfrozen\": all layers unfrozen\n","\"frozen\": some transformer layers frozen\n","\"\"\"\n","_frozen = \"unfrozen\"\n","\n","\"\"\"\n","Location of training dataset.\n","\"True\": HuggingFace Hub\n","\"False\": local directory\n","\"\"\"\n","_from_hub = True\n","\n","\"\"\"\n","Name of dataset on HuggingFace Hub.\n","\"\"\"\n","_dataset_name_hub = \"HalaJada/FinStmts_ConsUncons_Sliding_English_SeqClass\"\n","\n","\"\"\"\n","Name of directory that contains the local dataset.\n","\"\"\"\n","_dataset_name_local = \"\"\n","\n","\"\"\"\n","Boolean flag to indicate majority voting/multi-segment approach\n","\"\"\"\n","_flag_mv = True\n","\n","\"\"\"\n","Name of HPS study\n","\"\"\"\n","_study_name = \"test\""]},{"cell_type":"markdown","source":["## Define hyperparameter search space"],"metadata":{"id":"usSM8XD5d4GQ"}},{"cell_type":"code","source":["\"\"\"\n","Adjust hyperparameters and their ranges as desired\n","\n","https://huggingface.co/docs/transformers/en/hpo_train\n","\"\"\"\n","# Define hp space function\n","def optuna_hp_space(trial):\n","  return  {\"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n","           \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16]),\n","           \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-5, 1e-1),\n","           \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0, 1e-1),}"],"metadata":{"id":"kC4tQXy9d3Ax","executionInfo":{"status":"ok","timestamp":1708013970980,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7XKUOLSgcwNH"},"source":["# Configure using ModelConfig (continuation of HPS)"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"mMDCFdG8cwNH","executionInfo":{"status":"ok","timestamp":1708013970980,"user_tz":-60,"elapsed":4,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"}}},"outputs":[],"source":["\"\"\"\n","If continuation of HPS study, config settings loaded from ModelConfig.\n","\"\"\"\n","if not _flag_first_run:\n","    _task = model_config.task\n","    _base_model = model_config.base_model\n","    _reset_model_head = model_config.reset_model_head\n","    _loss_fct = model_config.loss_fct\n","    _weight_scheme = model_config.weight_scheme\n","    _eval_metrics = model_config.eval_metrics\n","    _metric_best_model = model_config.metric_best_model\n","    _metric_direction = model_config.metric_direction\n","    _frozen = model_config.frozen\n","    _from_hub = model_config.from_hub\n","    _dataset_name_hub = model_config.dataset_name_hub\n","    _dataset_name_local = model_config.dataset_name_local\n","    _flag_mv = model_config.flag_mv\n","    _study_name = model_config.study_name"]},{"cell_type":"markdown","metadata":{"id":"IrZ91MToIwEf"},"source":["# Metadata"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1708013970980,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"},"user_tz":-60},"id":"iGkjtCJ6yAgG"},"outputs":[],"source":["\"\"\"\n","Timestamp of initial training. Used for file and directory naming schemes\n","\"\"\"\n","timestamp = datetime.now().strftime(\"%d_%m_%y_%H_%M\")\n","if not _flag_first_run:\n","    timestamp = model_config.timestamp_initial\n","\n","\"\"\"\n","Some model names contain '/' characters which create issues with file and directory pathing.\n","We replace them with '__' only for naming purposes\n","\"\"\"\n","base_model_altered = re.sub(r'/', '___', _base_model)\n","\n","\"\"\"\n","Name of dataset, used to name model_config. Also replaces \"/\" with \"_\".\n","\"\"\"\n","dataset_name = re.sub(r'/', '_',_dataset_name_hub) if _from_hub else _dataset_name_local\n","\n","\"\"\"\n","Directory path for training data.\n","\"\"\"\n","path_initial_training =  os.path.join(\"training_data\" , base_model_altered, \"initial_training\" + \"_\" + timestamp)\n","\n","\"\"\"\n","Select weighting scheme, only needed when using weighted cost functions.\n","Functions can be found in utility.utility.py\n","\"\"\"\n","class_weighting_schemes = {\"rev_prop\": util.get_reverse_prop_class_weights}\n","\n","\"\"\"\n","Path to folder with local dataset.\n","\"\"\"\n","path_dataset_local = os.path.join(\"datasets\" , _dataset_name_local)\n","\n","\"\"\"\n","Name and path to ModelConfig object file.\n","\"\"\"\n","file_modelconfig = \"ModelConfig_\" + base_model_altered + \"_\" + dataset_name + \"_\" + timestamp + \".pkl\"\n","path_file_modelconfig = os.path.join(\"modelconfigs\", file_modelconfig)\n","\n","\"\"\"\n","Path to sqlite-database with optuna HPS-study data.\n","\"\"\"\n","path_study_db = os.path.join(\"study_dbs\", _study_name + \"_\" + base_model_altered + \"_\" + dataset_name + \"_\" + timestamp + \".db\")"]},{"cell_type":"markdown","metadata":{"id":"hYAAghnjIzBt"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"YVotGcMsQLKC"},"source":["## Load Data"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":2676,"status":"ok","timestamp":1708013973652,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"},"user_tz":-60},"id":"dnPxVcJqQLSC"},"outputs":[],"source":["raw_datasets = util.load_data(_from_hub, _dataset_name_hub, os.path.join(path_cwd, path_dataset_local))"]},{"cell_type":"markdown","metadata":{"id":"0QneNeqTcwNK"},"source":["## Determine number of labels/classes"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"wnSbqiV-cwNL","executionInfo":{"status":"ok","timestamp":1708013974007,"user_tz":-60,"elapsed":357,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"}}},"outputs":[],"source":["num_labels = util.get_no_labels(raw_datasets)"]},{"cell_type":"markdown","metadata":{"id":"dTd5NK-PcwNL"},"source":["## Determine class weights"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"GMgk9a8scwNL","executionInfo":{"status":"ok","timestamp":1708013974007,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"}}},"outputs":[],"source":["class_weights = class_weighting_schemes[_weight_scheme](raw_datasets)\n","if not _flag_first_run:\n","    class_weights = model_config.class_weights"]},{"cell_type":"markdown","metadata":{"id":"dY2CaIW5QCY3"},"source":["## Load Tokenizer"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":485,"status":"ok","timestamp":1708013974488,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"},"user_tz":-60},"id":"w7qbphxLQAia"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(_base_model)"]},{"cell_type":"markdown","metadata":{"id":"1MUIwuMIQ0Hx"},"source":["## Function that returns the Tokenizer - needed to employ data mapping.\n","\n","Note: Adjust this to desired task."]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1708013974489,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"},"user_tz":-60},"id":"6F83g3QqQAo3"},"outputs":[],"source":["def tokenize_function(example):\n","    return tokenizer(example[\"text\"], truncation=True)"]},{"cell_type":"markdown","metadata":{"id":"EwQnmO5sRKgG"},"source":["## Tokenize dataset"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":3108,"status":"ok","timestamp":1708013977589,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"},"user_tz":-60},"id":"QKBC_DDhc0sY","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["0755b3ee5adc4ba39f9927706941cb42","50e309d486414738b04673be4ac7f45a","9dab26f042614923be9bee458668cedf","cd3b563c7a324b52bf8c4f797d99d9a8","978aa5431cd045718b2bb13ddb46ad46","7998a3d4a1cc4708854e7b5467002b61","3d34110be74e42c7ba1dbeab256f4c6e","d70ad0bd7bb042cc872867b8bc2ead02","48b17c823b7c4307a7d604a85a352d91","572fe5b987d043ffaa33259ddac74163","fb522418efd2488e9fb3b99446e4c216"]},"outputId":"1fd88681-1346-4a87-982b-29708558c417"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2088 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0755b3ee5adc4ba39f9927706941cb42"}},"metadata":{}}],"source":["tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"]},{"cell_type":"markdown","metadata":{"id":"CvgXUeGJRZEg"},"source":["## Instantiate DataCollator\n","Note: DataCollatorWithPadding allows for dynamic padding for individual batches. Only use with GPUs. For TPUs, use max_length padding attribute with Tokenizer instance."]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1708013977589,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"},"user_tz":-60},"id":"LWJoWdWJRZMe"},"outputs":[],"source":["data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"WJWBvuj_JL8y"},"source":["## Create instance of TrainingArguments\n","\n","Adjust to desired behaviour. Most arguments learned during hyperparameter-search."]},{"cell_type":"code","execution_count":41,"metadata":{"id":"2xFvipTPcwNN","executionInfo":{"status":"ok","timestamp":1708013977589,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"}}},"outputs":[],"source":["\"\"\"\n","Create instance of class TrainingArguments.\n","\"\"\"\n","training_args = TrainingArguments(\n","    output_dir = os.path.join(path_cwd, path_initial_training),\n","    save_strategy = _save_strategy,\n","    evaluation_strategy = \"epoch\",\n","    logging_strategy = \"epoch\",\n","    metric_for_best_model = _metric_best_model,\n","    disable_tqdm = _disable_tqdm,\n","    )"]},{"cell_type":"markdown","metadata":{"id":"tjtjOcw3JQ-E"},"source":["## Model Initialzation"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"Baab8eAKcwNO","executionInfo":{"status":"ok","timestamp":1708013977590,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"}}},"outputs":[],"source":["\"\"\"\n","Here we supply two model init functions, one that freezes a number of encoder layers and\n","one that leaves all unfrozen.\n","\n","Pass desired init function to Trainer below.\n","\n","Gradual unfreezing helps to strike a balance between leveraging pre-trained\n","knowledge and adapting to task-specific data. By unfreezing layers gradually\n","during training, the model learns to prioritize retaining general linguistic\n","knowledge in the early layers while fine-tuning the higher layers to adapt to\n","task-specific nuances. This mitigates overfitting by allowing the model to\n","gradually specialize on the new task without abruptly forgetting the\n","linguistic representations learned during pre-training, resulting in more\n","effective adaptation and improved generalization to the target task.\n","\n","Note: When utilizing gradual unfreezing you will have to train the model in\n","multiple steps. Gradually unfreezing ever more layers during training.\n","You will observe slower convergence, as such this will take more time.\n","\n","Note: Depending on the choice of a base model and the desired number of layers\n","to freeze the model_init_frozen function might have to be adjusted.\n","To see which layers are available run:\n","\n","  for name, param in model.named_parameters():\n","    print(name, param)\n","\n","Observe entire model architecture and note layers you wish to freeze. Adjust\n","*conditional statement accordingly.\n","\n","# https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751\n","\"\"\"\n","\n","\n","def model_init_frozen(freeze_layers):\n","  model = AutoModelForSequenceClassification.from_pretrained(_base_model, num_labels=num_labels, return_dict=True, ignore_mismatched_sizes=_reset_model_head)\n","  for name, param in model.named_parameters():\n","    # *conditional statement: currently all encoder layers are frozen\n","    freeze_layers = [\"layer.\" + str(i) for i in range(11)]\n","    for fl in freeze_layers:\n","      if fl in name:\n","        param.requires_grad = False\n","  return model\n","\n","def model_init():\n","  return AutoModelForSequenceClassification.from_pretrained(_base_model, num_labels=num_labels, return_dict=True, ignore_mismatched_sizes = _reset_model_head)\n","\n","\n","model_inits = {\"unfrozen\": model_init, \"frozen\": model_init_frozen}"]},{"cell_type":"markdown","metadata":{"id":"G2buqPQQcwNO"},"source":["## Create evaluation metric object and compute function to pass to Trainer."]},{"cell_type":"code","execution_count":43,"metadata":{"id":"LwYTGESqcwNP","executionInfo":{"status":"ok","timestamp":1708013982114,"user_tz":-60,"elapsed":4529,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"}}},"outputs":[],"source":["clf_metrics = evaluate.combine(_eval_metrics)\n","\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","    return clf_metrics.compute(predictions = predictions, references = labels)"]},{"cell_type":"markdown","metadata":{"id":"YvjtaX67SAxi"},"source":["## Initialize CustomTrainer"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1580,"status":"ok","timestamp":1708013983680,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"},"user_tz":-60},"id":"YvWoN2ipR71V","outputId":"b24430bc-9e14-4f21-c870-66aa64a5e773"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["trainer = ct.CustomTrainer(\n","    type_loss = _loss_fct,\n","    model_init = model_inits[_frozen],\n","    class_weights = class_weights,\n","    args = training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics = compute_metrics,\n",")"]},{"cell_type":"markdown","metadata":{"id":"zSa9_xPWcwNP"},"source":["## Create and add CustomCallback to Trainer. Allows us to save training logs after each hyperparameter trial run."]},{"cell_type":"code","execution_count":45,"metadata":{"id":"bV8SHFCrcwNP","executionInfo":{"status":"ok","timestamp":1708013983680,"user_tz":-60,"elapsed":9,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"}}},"outputs":[],"source":["callback = cb.CustomCallback(trainer)\n","trainer.add_callback(callback)"]},{"cell_type":"markdown","metadata":{"id":"jJ7ygag4SIFV"},"source":["## (Optional) Create and assign an Optimizer and Scheduler\n","\n","When using the HuggingFace Trainer API for hyperparameter search, we can no longer use the \"optimizer\" argument directly. Instead we need to create instances of both the optimizer and scheduler class, and then pass both to Trainer object.\n","\n","Note: This is optional, as we could skip the following step and use the defaults. Included in case some custom behaviour is desired. Remove \"#\" to uncomment passing of objects."]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1708013983681,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"},"user_tz":-60},"id":"DjaTybKZR75P","outputId":"f723b6db-cff4-4568-98be-0e5249cefbf3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nPass instances to Trainer\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":46}],"source":["optimizer = torch.optim.AdamW(trainer.model.parameters())\n","lr_scheduler = get_scheduler(\n","    \"linear\",\n","    optimizer = optimizer,\n","    num_warmup_steps = 0,\n","    num_training_steps = training_args.num_train_epochs * tokenized_datasets[\"train\"].num_rows\n","\n",")\n","\n","\"\"\"\n","Pass instances to Trainer\n","\"\"\"\n","#trainer.optimizers = (optimizer, lr_scheduler)"]},{"cell_type":"markdown","metadata":{"id":"LzY5_Rkj5DsG"},"source":["# Hyperparameter Search via Optuna\n","\n","https://towardsdatascience.com/state-of-the-art-machine-learning-hyperparameter-optimization-with-optuna-a315d8564de1\n","\n","https://huggingface.co/docs/transformers/hpo_train\n","\n","https://github.com/bayesian-optimization/BayesianOptimization\n","\n"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1708013983681,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"},"user_tz":-60},"id":"otwC5-wurHsq"},"outputs":[],"source":["# Define objective function that later selects best model based upon specific metric\n","def compute_objective(metrics):\n","  return metrics[_metric_best_model]"]},{"cell_type":"markdown","metadata":{"id":"O7ILtPjkStWa"},"source":["## Run Hyperparameter Search"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"elapsed":982600,"status":"ok","timestamp":1708014966273,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"},"user_tz":-60},"id":"nk8zx24BStiR","outputId":"30a673d8-72f7-4f29-c79e-c91cdf7b7c9f"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-15 16:19:43,601] Using an existing study with name 'test' instead of creating a new one.\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3672' max='3672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3672/3672 16:20, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Matthews Correlation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.369600</td>\n","      <td>0.299435</td>\n","      <td>0.918103</td>\n","      <td>0.899585</td>\n","      <td>0.955908</td>\n","      <td>0.926892</td>\n","      <td>0.835988</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.241600</td>\n","      <td>0.350481</td>\n","      <td>0.915230</td>\n","      <td>0.918635</td>\n","      <td>0.925926</td>\n","      <td>0.922266</td>\n","      <td>0.829094</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.185000</td>\n","      <td>0.383426</td>\n","      <td>0.920019</td>\n","      <td>0.915021</td>\n","      <td>0.940035</td>\n","      <td>0.927360</td>\n","      <td>0.838801</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-02-15 16:36:06,159] Trial 1 finished with value: 0.8388013145422787 and parameters: {'learning_rate': 3.3832004014874405e-06, 'per_device_train_batch_size': 8, 'weight_decay': 0.07033272431094277, 'warmup_ratio': 0.03261355702757888}. Best is trial 0 with value: 0.8445874580883338.\n"]},{"output_type":"execute_result","data":{"text/plain":["BestRun(run_id='0', objective=0.8445874580883338, hyperparameters={'learning_rate': 7.6212896216059535e-06, 'per_device_train_batch_size': 8, 'weight_decay': 0.08356915016884235, 'warmup_ratio': 0.05345476274234841}, run_summary=None)"]},"metadata":{},"execution_count":48}],"source":["# Run hyperparameter search\n","best_run = trainer.hyperparameter_search(\n","    direction=_metric_direction,\n","    backend=\"optuna\",\n","    hp_space = optuna_hp_space,\n","    n_trials = _num_trials,\n","    compute_objective = compute_objective,\n","    study_name=_study_name,\n","    storage= \"sqlite:///\" + os.path.join(path_cwd, path_study_db),\n","    load_if_exists=True,\n","    )\n","best_run"]},{"cell_type":"markdown","metadata":{"id":"p1x7wwl0cwNa"},"source":["## Process HPS log history"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"gefZjmnmcwNa","executionInfo":{"status":"ok","timestamp":1708014966606,"user_tz":-60,"elapsed":347,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"}}},"outputs":[],"source":["hps_log_df = util.process_hps_log_history(callback.all_log_history)"]},{"cell_type":"markdown","metadata":{"id":"ZbnYzg_kcwNa"},"source":["# Create ModelConfig File"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"OLnvjHd2cwNb","executionInfo":{"status":"ok","timestamp":1708014966607,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"}}},"outputs":[],"source":["if _flag_first_run:\n","    model_config = mc.ModelConfig(timestamp = timestamp,\n","                              base_model = _base_model,\n","                              reset_model_head = _reset_model_head,\n","                              task = _task,\n","                              loss_fct = _loss_fct,\n","\n","                              from_hub = _from_hub,\n","                              dataset_name_hub = _dataset_name_hub,\n","                              dataset_name_local = _dataset_name_local,\n","                              path_dataset_local = path_dataset_local,\n","\n","                              num_labels = num_labels,\n","                              weight_scheme = _weight_scheme,\n","                              class_weights = class_weights,\n","                              eval_metrics = _eval_metrics,\n","                              metric_best_model = _metric_best_model,\n","                              metric_direction = _metric_direction,\n","\n","                              num_trials = _num_trials,\n","                              frozen = _frozen,\n","                              path_initial_training = path_initial_training,\n","                              best_run = best_run,\n","                              hps_log_df = hps_log_df,\n","                              flag_mv = _flag_mv,\n","                              study_name = _study_name,\n","                              path_study_db = path_study_db,)\n","else:\n","    # update model_config\n","    model_config.no_trials = model_config.num_trials + _num_trials\n","    model_config.best_run = best_run\n","    model_config.hps_log_df = util.merge_hps_log_histories(model_config.hps_log_df, hps_log_df)"]},{"cell_type":"markdown","metadata":{"id":"5tAPuUgMgYrS"},"source":["# Save ModelConfig"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1708014966607,"user":{"displayName":"Ilias Matthias Nasri","userId":"17108654071466836904"},"user_tz":-60},"id":"7sOVEWcCgBsn"},"outputs":[],"source":["with open(os.path.join(path_cwd, path_file_modelconfig), 'wb') as f:\n","    pickle.dump(model_config, f)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"venv_ml_bert","language":"python","name":"venv_ml_bert"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0755b3ee5adc4ba39f9927706941cb42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_50e309d486414738b04673be4ac7f45a","IPY_MODEL_9dab26f042614923be9bee458668cedf","IPY_MODEL_cd3b563c7a324b52bf8c4f797d99d9a8"],"layout":"IPY_MODEL_978aa5431cd045718b2bb13ddb46ad46"}},"50e309d486414738b04673be4ac7f45a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7998a3d4a1cc4708854e7b5467002b61","placeholder":"​","style":"IPY_MODEL_3d34110be74e42c7ba1dbeab256f4c6e","value":"Map: 100%"}},"9dab26f042614923be9bee458668cedf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d70ad0bd7bb042cc872867b8bc2ead02","max":2088,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48b17c823b7c4307a7d604a85a352d91","value":2088}},"cd3b563c7a324b52bf8c4f797d99d9a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_572fe5b987d043ffaa33259ddac74163","placeholder":"​","style":"IPY_MODEL_fb522418efd2488e9fb3b99446e4c216","value":" 2088/2088 [00:03&lt;00:00, 675.12 examples/s]"}},"978aa5431cd045718b2bb13ddb46ad46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7998a3d4a1cc4708854e7b5467002b61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d34110be74e42c7ba1dbeab256f4c6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d70ad0bd7bb042cc872867b8bc2ead02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48b17c823b7c4307a7d604a85a352d91":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"572fe5b987d043ffaa33259ddac74163":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb522418efd2488e9fb3b99446e4c216":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}