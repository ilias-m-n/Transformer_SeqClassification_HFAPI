{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoiMafe4IZH2"
   },
   "source": [
    "# Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 13747,
     "status": "ok",
     "timestamp": 1706230448765,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "BzaTHUtWcb4T"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "from datasets import (\n",
    "     load_from_disk, \n",
    "     load_metric, \n",
    "     DatasetDict, \n",
    "     load_dataset\n",
    ")\n",
    "import evaluate\n",
    "from transformers import (\n",
    "     AutoTokenizer,\n",
    "     DataCollatorWithPadding,\n",
    "     TrainingArguments,\n",
    "     AutoModelForSequenceClassification,\n",
    "     Trainer,\n",
    "     logging,\n",
    "     AdamW,\n",
    "     get_scheduler,\n",
    "\n",
    ")\n",
    "import torch\n",
    "from ray import tune, train\n",
    "import pickle\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "import utility.utility as util\n",
    "import utility.CustomTrainer as ct\n",
    "import utility.ModelConfig as mc\n",
    "import utility.CustomCallback as cb\n",
    "\n",
    "# turn off warnings\n",
    "#logging.set_verbosity_error()\n",
    "\n",
    "# resets import once changes have been applied\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWD Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "path to local\n",
    "\"\"\"\n",
    "path_cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disable TQDM, for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "disable tqdm\n",
    "\"\"\"\n",
    "_disable_tqdm = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint Save Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save checkpoints during training, requires a lot of disk space\n",
    "\"\"\"\n",
    "_save_strategy = \"no\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Run or Restart of HPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag whether first run or continued study\n",
    "_flag_first_run = True\n",
    "\n",
    "# modelconfig file name\n",
    "_name_config_file = \"\"\n",
    "\n",
    "# path to model_config\n",
    "path_file_modelconfig = os.path.join(\"modelconfigs\", _name_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ModelConfig, if not first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss\n"
     ]
    }
   ],
   "source": [
    "model_config = None\n",
    "if not _flag_first_run:\n",
    "    with open(os.path.join(path_cwd, path_file_modelconfig), \"rb\") as f:\n",
    "        model_config = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "description of downstream task you want to train you model on\n",
    "\"\"\"\n",
    "_task = \"Binary Classification _ with study object and hps log history\"\n",
    "if not _flag_first_run:\n",
    "    _task = model_config.task\n",
    "\n",
    "\"\"\"\n",
    "Base BERT model to be used during finetuning.\n",
    "This has to be picked from the pre-trained models on HuggingFace\n",
    "in order to be compatible with the Trainer API\n",
    "\"\"\"\n",
    "_base_model = \"roberta-base\"\n",
    "if not _flag_first_run:\n",
    "    _base_model = model_config.base_model\n",
    "\n",
    "\"\"\"\n",
    "Three custom loss functions have been implemented:\n",
    "  f1: soft-f1 macro score\n",
    "  mcc: soft-mcc\n",
    "  wce: weighted cross entropy\n",
    "  ce: standard cross entropy\n",
    "\"\"\"\n",
    "_loss_fct = \"ce\"\n",
    "if not _flag_first_run:\n",
    "    _loss_fct = model_config.loss_fct\n",
    "    \n",
    "\"\"\"\n",
    "weighting scheme, only relevant when weighted-cross-entropy or other weighted losses are used\n",
    "\"\"\"\n",
    "_weight_scheme = \"rev_prop\"\n",
    "if not _flag_first_run:\n",
    "    _weight_scheme = model_config.weight_scheme\n",
    "  \n",
    "\n",
    "\"\"\"\n",
    "Metrics listed during evaluation:\n",
    "\n",
    "Note: adjust with desired metrics.\n",
    "\"\"\"\n",
    "_eval_metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"matthews_correlation\"]\n",
    "if not _flag_first_run:\n",
    "    _eval_metrics = model_config.eval_metrics\n",
    "  \n",
    "\n",
    "\"\"\"\n",
    "Specify which metric should be maximized/minimized during hyperparameter-search\n",
    "Options:\n",
    "- eval_matthews_correlation\n",
    "- eval_f1\n",
    "- eval_loss\n",
    "- any other metric passed to the compute_metrics function\n",
    "\n",
    "also specify direction: \"maximize\"/\"minimize\"\n",
    "\"\"\"\n",
    "_metric_best_model = \"eval_matthews_correlation\"\n",
    "if not _flag_first_run:\n",
    "    _metric_best_model = model_config.metric_best_model\n",
    "    \n",
    "_metric_direction = \"maximize\"\n",
    "if not _flag_first_run:\n",
    "    _metric_direction = model_config.metric_direction\n",
    "\n",
    "\"\"\"\n",
    "Number of trials to run during this run of hyperparameter search.\n",
    "\"\"\"\n",
    "_no_trials = 2\n",
    "\n",
    "\"\"\"\n",
    "Employ freezing of layers, options:\n",
    "\"unfrozen\": all layers unfrozen\n",
    "\"frozen\": all transformer layers frozen\n",
    "\"\"\"\n",
    "_frozen = \"unfrozen\"\n",
    "if not _flag_first_run:\n",
    "    _frozen = model_config.frozen\n",
    "\n",
    "\"\"\"\n",
    "location of dataset\n",
    "\"hub\": HuggingFace Hub\n",
    "\"local\": Local directory\n",
    "\"\"\"\n",
    "_from_hub = True\n",
    "if not _flag_first_run:\n",
    "    _from_hub = model_config.from_hub\n",
    "\n",
    "\"\"\"\n",
    "name of dataset on Hf-Hub\n",
    "\"\"\"\n",
    "_dataset_name_hub = \"HalaJada/FinStmts_ConsUncons_Sliding_English_SeqClass\"\n",
    "if not _flag_first_run:\n",
    "    _dataset_name_hub = model_config.dataset_name_hub\n",
    "\n",
    "\"\"\"\n",
    "name of local dataset\n",
    "\"\"\"\n",
    "_dataset_name_local = \"\"\n",
    "if not _flag_first_run:\n",
    "    _dataset_name_local = model_config.dataset_name_local\n",
    "    \n",
    "\"\"\"\n",
    "flag majority voting, multi-segment approach\n",
    "\"\"\"\n",
    "_flag_mv = False\n",
    "if not _flag_first_run:\n",
    "    _flag_mv = model_config.flag_mv\n",
    "\n",
    "\"\"\"\n",
    "hps study name\n",
    "\"\"\"\n",
    "_study_name = \"test\"\n",
    "if not _flag_first_run:\n",
    "    _study_name = model_config.study_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrZ91MToIwEf"
   },
   "source": [
    "# Set Global/Meta Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1706230452844,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "iGkjtCJ6yAgG"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "timestamp\n",
    "\"\"\"\n",
    "timestamp = datetime.now().strftime(\"%d_%m_%y_%H_%M\")\n",
    "if not _flag_first_run:\n",
    "    timestamp = model_config.timestamp_initial\n",
    "\n",
    "\"\"\"\n",
    "some model contain '/' characters which create issues with file and directory pathing, we replace them with '__' only for naming purposes\n",
    "\"\"\"\n",
    "# for saving name in model config we need to make sure that there is no '/' in _base_model\n",
    "base_model_altered = re.sub(r'/', '___', _base_model)\n",
    "\n",
    "\"\"\"\n",
    "name of dataset to name model_config\n",
    "\"\"\"\n",
    "dataset_name = re.sub(r'/', '_',_dataset_name_hub) if _from_hub else _dataset_name_local\n",
    "\n",
    "\"\"\"\n",
    "Directory Paths:\n",
    "\"\"\"\n",
    "path_initial_training =  os.path.join(\"training_data\" , base_model_altered, \"initial_training\" + \"_\" + timestamp)\n",
    "\n",
    "\"\"\"\n",
    "Select weighting method when using weighted cost functions.\n",
    "\"\"\"\n",
    "class_weighting_schemes = {\"rev_prop\": util.get_reverse_prop_class_weights}\n",
    "\n",
    "\"\"\"\n",
    "path to folder with local datasets\n",
    "\"\"\"\n",
    "path_dataset_local = os.path.join(\"datasets\" , _dataset_name_local)\n",
    "\n",
    "\"\"\"\n",
    "name of file with ModelConfig object\n",
    "path to folder with modelconfig\n",
    "\"\"\"\n",
    "file_modelconfig = \"ModelConfig_\" + base_model_altered + \"_\" + dataset_name + \"_\" + timestamp + \".pkl\"\n",
    "path_file_modelconfig = os.path.join(\"modelconfigs\", file_modelconfig)\n",
    "\n",
    "\"\"\"\n",
    "path to sqlite database with the optuna study parameters\n",
    "\"\"\"\n",
    "path_study_db = os.path.join(\"study_dbs\", _study_name + \"_\" + base_model_altered + \"_\" + dataset_name + \"_\" + timestamp + \".db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYAAghnjIzBt"
   },
   "source": [
    "# Setup\n",
    "\n",
    "This part has to be adjusted to whatever dataset and format used.\n",
    "\n",
    "Note: DataCollatorWithPadding allows for dynamic padding for individual batches. Only use with GPUs. For TPUs, use max_length padding attribute with Tokenizer instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVotGcMsQLKC"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "Either load from a local directory or from the HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1706230452844,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "dnPxVcJqQLSC"
   },
   "outputs": [],
   "source": [
    "raw_datasets = util.load_data(_from_hub, _dataset_name_hub, os.path.join(path_cwd, path_dataset_local))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine number of labels/classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = util.get_no_labels(raw_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weighting_schemes[_weight_scheme](raw_datasets)\n",
    "if not _flag_first_run:\n",
    "    class_weights = model_config.class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dY2CaIW5QCY3"
   },
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3178,
     "status": "ok",
     "timestamp": 1706230456007,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "w7qbphxLQAia",
    "outputId": "a5abb768-5382-4ba6-ba17-ee09ade93c44"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(_base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MUIwuMIQ0Hx"
   },
   "source": [
    "## Function that returns the Tokenizer so that we can employ data mapping.\n",
    "\n",
    "Note: Adjust this to desired task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1706230456008,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "6F83g3QqQAo3"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwQnmO5sRKgG"
   },
   "source": [
    "## Map Dataset with Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2328,
     "status": "ok",
     "timestamp": 1706230458326,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "QKBC_DDhc0sY"
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvgXUeGJRZEg"
   },
   "source": [
    "## Instantiate DataCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1706230458327,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "LWJoWdWJRZMe"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJWBvuj_JL8y"
   },
   "source": [
    "# Training Arguments\n",
    "\n",
    "Adjust to desired behaviour. Most arguments can be learned during hyperparameter-search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1706230458327,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "O9t82JVzjz4j"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create instance of class TrainingArguments. Adjust to desired behaviour.\n",
    "\"\"\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = os.path.join(path_cwd, path_initial_training),\n",
    "    save_strategy = _save_strategy,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    logging_strategy = \"epoch\",\n",
    "    metric_for_best_model = _metric_best_model,\n",
    "    disable_tqdm = _disable_tqdm,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjtjOcw3JQ-E"
   },
   "source": [
    "# Model Initialzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model Initilization\n",
    "\n",
    "Here we supply two model init functions, one that freezes all encoder layers and\n",
    "one that does not.\n",
    "\n",
    "Pass desired init function to Trainer below.\n",
    "\n",
    "Gradual unfreezing helps to strike a balance between leveraging pre-trained\n",
    "knowledge and adapting to task-specific data. By unfreezing layers gradually\n",
    "during training, the model learns to prioritize retaining general linguistic\n",
    "knowledge in the early layers while fine-tuning the higher layers to adapt to\n",
    "task-specific nuances. This mitigates overfitting by allowing the model to\n",
    "gradually specialize on the new task without abruptly forgetting the\n",
    "linguistic representations learned during pre-training, resulting in more\n",
    "effective adaptation and improved generalization to the target task.\n",
    "\n",
    "Note: When utilizing gradual unfreezing you will have to train the model in\n",
    "multiple steps. Gradually unfreezing ever more layers during training.\n",
    "You will observe slower convergence, as such this will take more time.\n",
    "\n",
    "Note: Depending on the choice of a base model and the desired number of layers\n",
    "to freeze the model_init_frozen function might have to be adjusted.\n",
    "To see which layers are available run:\n",
    "\n",
    "  for name, param in model.named_parameters():\n",
    "    print(name, param)\n",
    "\n",
    "Observe entire model architecture and note layers you wish to freeze. Adjust\n",
    "*conditional statement accordingly.\n",
    "\n",
    "# https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def model_init_frozen(freeze_layers):\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(_base_model, num_labels=num_labels, return_dict=True)\n",
    "  for name, param in model.named_parameters():\n",
    "    # *conditional statement: currently all encoder layers are frozen\n",
    "    freeze_layers = [\"layer.\" + str(i) for i in range(11)]\n",
    "    for fl in freeze_layers:\n",
    "      if fl in name:\n",
    "        param.requires_grad = False\n",
    "  return model\n",
    "\n",
    "def model_init():\n",
    "  return AutoModelForSequenceClassification.from_pretrained(_base_model, num_labels=num_labels, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1706230458328,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "wibKu7-clCxD"
   },
   "outputs": [],
   "source": [
    "model_inits = {\"unfrozen\": model_init, \"frozen\": model_init_frozen}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluation Metrics\n",
    "\n",
    "Below we specify which performance measures we wish to observe during training\n",
    "at the end of each step/epoch.\n",
    "\n",
    "And provide a metric function for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_metrics = evaluate.combine(_eval_metrics)\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return clf_metrics.compute(predictions = predictions, references = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvjtaX67SAxi"
   },
   "source": [
    "# Initialize CustomTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5134,
     "status": "ok",
     "timestamp": 1706230474466,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "YvWoN2ipR71V",
    "outputId": "9c58e942-0787-459e-ef4b-e90a046b375f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = ct.CustomTrainer(\n",
    "    type_loss = _loss_fct,\n",
    "    model_init = model_inits[_frozen],\n",
    "    class_weights = class_weights,\n",
    "    args = training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Add Callback to save training logs after each hyperparameter trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = cb.CustomCallback(trainer)\n",
    "trainer.add_callback(callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJ7ygag4SIFV"
   },
   "source": [
    "# (Optional) Create and assign an Optimizer and Scheduler\n",
    "\n",
    "When using the HuggingFace Trainer API for hyperparameter search, we can no longer use the \"optimizer\" argument directly. Instead we customize the optimizer and scheduler\n",
    "\n",
    "Note: This is rather optional, as we could skip the following step and use the defaults. Inclusion in case some custom behaviour is desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1706230474466,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "DjaTybKZR75P",
    "outputId": "8a030538-588d-4b87-ab8e-3b9e8cb1e4dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPass instances to Trainer\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "When using the HugginFace Trainer API for hyperparameter search, we can no longer use\n",
    "the \"optimizer\" argument directly. Instead we customize the optimizer and scheduler\n",
    "\"\"\"\n",
    "optimizer = torch.optim.AdamW(trainer.model.parameters())\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = training_args.num_train_epochs * tokenized_datasets[\"train\"].num_rows\n",
    "\n",
    ")\n",
    "\n",
    "# Uncomment line below if you wish to pass objects to Trainer\n",
    "\"\"\"\n",
    "Pass instances to Trainer\n",
    "\"\"\"\n",
    "#trainer.optimizers = (optimizer, lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzY5_Rkj5DsG"
   },
   "source": [
    "# Hyperparameter Search via Optuna\n",
    "\n",
    "Adjust hyperparameters and their ranges as desired\n",
    "\n",
    "\n",
    "Note: warmup_ratio fulfills a somewhat similar role to freezing. It is also often used to stabilize training at the beginning and avoid large weight updates.\n",
    "\n",
    "https://towardsdatascience.com/state-of-the-art-machine-learning-hyperparameter-optimization-with-optuna-a315d8564de1\n",
    "\n",
    "https://huggingface.co/docs/transformers/hpo_train\n",
    "\n",
    "https://github.com/bayesian-optimization/BayesianOptimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1706230474466,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "otwC5-wurHsq"
   },
   "outputs": [],
   "source": [
    "# Define objective function that later selects best model based upon specific metric\n",
    "def compute_objective(metrics):\n",
    "  return metrics[_metric_best_model]\n",
    "\n",
    "# Define search space for hyperparamter tuning\n",
    "def optuna_hp_space(trial):\n",
    "  return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16]),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 3),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-5, 1e-1),\n",
    "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0, 1e-1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7ILtPjkStWa"
   },
   "source": [
    "# Run Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 9443600,
     "status": "ok",
     "timestamp": 1706239918060,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "nk8zx24BStiR",
    "outputId": "7856031a-a010-4b67-c0ca-4537ac02ad86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 00:54:33,832] A new study created in memory with name: no-name-0c47a83c-86ee-4ffe-a94e-1690a621e8e6\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1896' max='1896' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1896/1896 56:28, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.485900</td>\n",
       "      <td>0.081750</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.463700</td>\n",
       "      <td>0.080865</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.511700</td>\n",
       "      <td>0.078562</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.057659</td>\n",
       "      <td>0.991390</td>\n",
       "      <td>0.992583</td>\n",
       "      <td>0.998756</td>\n",
       "      <td>0.995660</td>\n",
       "      <td>0.496593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.058162</td>\n",
       "      <td>0.990160</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>0.550580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.057192</td>\n",
       "      <td>0.993850</td>\n",
       "      <td>0.993820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996900</td>\n",
       "      <td>0.664603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.065918</td>\n",
       "      <td>0.991390</td>\n",
       "      <td>0.995031</td>\n",
       "      <td>0.996269</td>\n",
       "      <td>0.995649</td>\n",
       "      <td>0.584934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>0.062628</td>\n",
       "      <td>0.993850</td>\n",
       "      <td>0.995043</td>\n",
       "      <td>0.998756</td>\n",
       "      <td>0.996896</td>\n",
       "      <td>0.677627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 01:51:08,718] Trial 0 finished with value: 0.6776274497306741 and parameters: {'learning_rate': 2.5807768691598085e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 8, 'weight_decay': 0.08270255272065924, 'warmup_ratio': 0.054434248236845895}. Best is trial 0 with value: 0.6776274497306741.\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1896' max='1896' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1896/1896 28:42, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.439100</td>\n",
       "      <td>0.163711</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>0.113970</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.100875</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.251500</td>\n",
       "      <td>0.097597</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 02:19:54,556] Trial 1 finished with value: 0.0 and parameters: {'learning_rate': 1.4505137694442436e-06, 'per_device_train_batch_size': 8, 'num_train_epochs': 4, 'weight_decay': 0.0861989407754196, 'warmup_ratio': 0.049334454425836775}. Best is trial 0 with value: 0.6776274497306741.\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2370' max='2370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2370/2370 35:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.357600</td>\n",
       "      <td>0.101555</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.083353</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.277900</td>\n",
       "      <td>0.081529</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.293800</td>\n",
       "      <td>0.081625</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>0.081800</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 02:55:55,949] Trial 2 finished with value: 0.0 and parameters: {'learning_rate': 3.171986659227783e-06, 'per_device_train_batch_size': 8, 'num_train_epochs': 5, 'weight_decay': 0.03382298794320742, 'warmup_ratio': 0.03144655413905456}. Best is trial 0 with value: 0.6776274497306741.\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2370' max='2370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2370/2370 35:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.381500</td>\n",
       "      <td>0.114150</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.237100</td>\n",
       "      <td>0.087455</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.265400</td>\n",
       "      <td>0.082703</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>0.081736</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>0.081591</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 03:31:56,860] Trial 3 finished with value: 0.0 and parameters: {'learning_rate': 2.531985663156513e-06, 'per_device_train_batch_size': 8, 'num_train_epochs': 5, 'weight_decay': 0.020163056253844593, 'warmup_ratio': 0.039555475521001394}. Best is trial 0 with value: 0.6776274497306741.\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter search\n",
    "best_run = trainer.hyperparameter_search(\n",
    "    direction=_metric_direction,\n",
    "    backend=\"optuna\",\n",
    "    hp_space = optuna_hp_space,\n",
    "    n_trials = _no_trials,\n",
    "    compute_objective = compute_objective,\n",
    "    study_name=_study_name,\n",
    "    storage= \"sqlite:///\" + os.path.join(path_cwd, path_study_db),\n",
    "    load_if_exists=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1706239918061,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "HgJwNcvpPf2P",
    "outputId": "6ee5846c-5eff-4ed0-f527-245b7b4e1719"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BestRun(run_id='0', objective=0.6776274497306741, hyperparameters={'learning_rate': 2.5807768691598085e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 8, 'weight_decay': 0.08270255272065924, 'warmup_ratio': 0.054434248236845895}, run_summary=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outputs best hyperparameters that lead to maximizing the objective function\n",
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process hps log history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps_log_df = util.process_hps_log_history(callbacks.all_log_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ModelConfig File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _flag_first_run:\n",
    "    model_config = mc.ModelConfig(timestamp = timestamp, \n",
    "                              base_model = _base_model, \n",
    "                              task = _task, \n",
    "                              loss_fct = _loss_fct, \n",
    "\n",
    "                              from_hub = _from_hub,\n",
    "                              dataset_name_hub = _dataset_name_hub,\n",
    "                              dataset_name_local = _dataset_name_local,\n",
    "                              path_dataset_local = path_dataset_local, \n",
    "\n",
    "                              num_labels = num_labels,\n",
    "                              weight_scheme = _weight_scheme, \n",
    "                              class_weights = class_weights,\n",
    "                              eval_metrics = _eval_metrics,\n",
    "                              metric_best_model = _metric_best_model, \n",
    "                              metric_direction = _metric_direction,\n",
    "                              \n",
    "                              no_trials = _no_trials,  \n",
    "                              frozen = _frozen,  \n",
    "                              path_initial_training = path_initial_training,\n",
    "                              best_run = best_run,\n",
    "                              hps_log_df = hps_log_df,\n",
    "                              flag_mv = _flag_mv,\n",
    "                              study_name = _study_name,\n",
    "                              path_study_db = path_study_db)\n",
    "else:\n",
    "    model_config.no_trials = model_config.no_trials + _no_trials\n",
    "    model_config.best_run = best_run\n",
    "    model_config.hps_log_df = util.merge_hps_log_histories(model_config.hps_log_df, hps_log_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tAPuUgMgYrS"
   },
   "source": [
    "# Save ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1706239918061,
     "user": {
      "displayName": "Ilias Matthias Nasri",
      "userId": "17108654071466836904"
     },
     "user_tz": -60
    },
    "id": "7sOVEWcCgBsn"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(path_cwd, path_file_modelconfig), 'wb') as f:\n",
    "    pickle.dump(model_config, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv_ml_bert",
   "language": "python",
   "name": "venv_ml_bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
